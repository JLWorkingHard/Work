{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS680_A1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86KGcC2dBA8X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "####################################exercise 1################################\n",
        "#Read csv file and store data in numpy format\n",
        "spambase_X = np.loadtxt('./spambase_X.csv',delimiter=',')\n",
        "spambase_y = np.loadtxt('./spambase_y.csv',delimiter=',')\n",
        "X = spambase_X.T\n",
        "y = spambase_y\n",
        "n,d = X.shape\n",
        "w = np.zeros(d)\n",
        "#define perceptron function\n",
        "def perceptron(X,y,w,b=0,max_pass=500):\n",
        "  global n\n",
        "  mistake = np.zeros(max_pass)\n",
        "  for t in range(max_pass):\n",
        "    for i in range(n):\n",
        "      if (y[i]*(w.T.dot(X[i]) + b) <= 0):\n",
        "        w = w + y[i]*X[i]\n",
        "        b = b + y[i]\n",
        "        mistake[t] = mistake[t] + 1\n",
        "\n",
        "  return mistake\n",
        "#generate plot for exercise 1\n",
        "m = perceptron(X,y,w)\n",
        "plt.plot(m)\n",
        "plt.title('number of passes vs. number of mistakes')\n",
        "plt.xlabel('number of passes')\n",
        "plt.ylabel('number of mistakes')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "####################################exercise 2################################\n",
        "#Read csv file and store data in numpy format\n",
        "house_X_train = np.loadtxt('./housing_X_train.csv',delimiter=',')\n",
        "house_y_train = np.loadtxt('./housing_y_train.csv',delimiter=',')\n",
        "house_X_test = np.loadtxt('./housing_X_test.csv',delimiter=',')\n",
        "house_y_test = np.loadtxt('./housing_y_test.csv',delimiter=',')\n",
        "#tranform to numpy array format\n",
        "house_X_train = np.mat(house_X_train).T\n",
        "house_X_test = np.mat(house_X_test).T\n",
        "house_y_train = np.mat(house_y_train).T\n",
        "house_y_test = np.mat(house_y_test).T\n",
        "def closed_form(X,y,lam):\n",
        "  n,d = X.shape\n",
        "  n_ones = np.ones(y.shape)\n",
        "  d_ones = np.ones((d,1))\n",
        "  X_2 = X.T.dot(X) #d*d\n",
        "  X_y = X.T.dot(y) #d*1\n",
        "  for i in range(X_2.shape[0]):\n",
        "    X_2[i,i] += 2*n*lam\n",
        "  b_vec = np.dot(X.T,n_ones) #d*1\n",
        "  X_2 = np.append(X_2,b_vec,axis=1)\n",
        "  a = X\n",
        "  a = np.append(a,n_ones,axis=1)\n",
        "  a = n_ones.T.dot(a)\n",
        "  b = n_ones.T*y\n",
        "  a = np.append(X_2,a,axis=0)\n",
        "  b = np.append(X_y,b,axis=0)\n",
        "  ans = np.linalg.solve(a,b)\n",
        "  w = ans[0:-1,0]\n",
        "  b = ans[-1,0]\n",
        "  return w,b"
      ],
      "metadata": {
        "id": "jCPV9UpaSTWB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient(X,y,w,b,lam):\n",
        "  n,d = X.shape\n",
        "  n_ones = np.ones(y.shape)\n",
        "  alpha = X.dot(w)+b*n_ones-y\n",
        "  dw = (1/n)*np.dot(X.T,alpha) + 2*lam*w\n",
        "  db = (1/n)*np.dot(n_ones.T,alpha)\n",
        "  return dw,db\n",
        "def error_func(X,y,w,b):\n",
        "  n = X.shape[0]\n",
        "  ones = np.ones((n,1))\n",
        "  alpha = np.dot(X,w) + b*ones - y\n",
        "  return np.dot(alpha.T,alpha)/(2*n)\n",
        "def loss_func(X,y,w,b,lam):\n",
        "  return error_func(X,y,w,b) + lam*np.dot(w.T,w)\n",
        "\n",
        "def ridge_regression(X,y,X_test,y_test,max_pass,eta,tol,lam):\n",
        "  w = np.zeros((X.shape[1],1))\n",
        "  b = 0\n",
        "  loss_train = []\n",
        "  for t in range(max_pass):\n",
        "    dw,db = gradient(X,y,w,b,lam)\n",
        "    w_new = w - eta*dw\n",
        "    b_new = b - eta*db[0,0]\n",
        "    loss_train.append(loss_func(X,y,w_new,b_new,lam)[0,0])\n",
        "    if np.linalg.norm((w_new-w),ord = 1) <= tol:\n",
        "      w = w_new\n",
        "      b = b_new\n",
        "      break\n",
        "    w,b = w_new,b_new\n",
        "  error_train = error_func(X,y,w_new,b_new)[0,0]\n",
        "  error_test = error_func(X_test,y_test,w_new,b_new)[0,0]\n",
        "  return loss_train,error_train,error_test,w,b\n",
        "def standarization(X_train,X_test):\n",
        "  X = np.vstack((X_train,X_test))\n",
        "  n,d = X.shape\n",
        "  m = np.zeros(d)\n",
        "  sd = np.zeros(d)\n",
        "  X_sd = np.zeros((n,d))\n",
        "  for i in range(n):\n",
        "    for j in range(d):\n",
        "      m[j] = np.mean(X[:,j])\n",
        "      sd[j] = np.std(X[:,j])\n",
        "      X_sd[i,j] = (X[i,j]-m[j])/sd[j]\n",
        "  X_train_sd = X_sd[0:X_train.shape[0]]\n",
        "  X_test_sd = X_sd[X_train.shape[0]:n]\n",
        "  return X_train_sd,X_test_sd"
      ],
      "metadata": {
        "id": "UUL7JZ46pet0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time as t\n",
        "n_test,d_test = house_X_test.shape\n",
        "n,d = house_X_train.shape\n",
        "l = [0,10]\n",
        "print('when input data is not standarized')\n",
        "print('for closed form solution')\n",
        "for lam in l:\n",
        "  print('when lambda equals to {0}'.format(lam))\n",
        "  start = t.time()\n",
        "  w,b = closed_form(house_X_train,house_y_train,lam)\n",
        "  end = t.time()\n",
        "  time_diff = end - start\n",
        "  print('time used equals to {0}'.format(time_diff))\n",
        "  print('the train loss is {0}'.format(loss_func(house_X_train,house_y_train,w,b,lam)))\n",
        "  print('the train error is {0}'.format(error_func(house_X_train,house_y_train,w,b)))\n",
        "  print('the test error is {0}'.format(error_func(house_X_test,house_y_test,w,b)))\n",
        "print('for gradient descent solution')\n",
        "for lam in l:\n",
        "  print('when lambda equals to {0}'.format(lam))\n",
        "  start = t.time()\n",
        "  loss_train,error_train,error_test,w,b = ridge_regression(house_X_train,house_y_train,house_X_test,house_y_test,max_pass=500,eta=0.01,tol=0.000001,lam=lam)\n",
        "  end = t.time()\n",
        "  time_diff = end -start\n",
        "  print('time used equals to {0}'.format(time_diff))\n",
        "  print('the train error is {0}'.format(error_func(house_X_train,house_y_train,w,b)))\n",
        "  print('the test error is {0}'.format(error_func(house_X_test,house_y_test,w,b)))\n",
        "  plt.figure()\n",
        "  plt.plot(loss_train)\n",
        "  plt.xlabel('passes')\n",
        "  plt.ylabel('train loss')\n",
        "  plt.title('passes vs. train loss')\n",
        "  plt.show()\n",
        "house_X_train,house_X_test = standarization(house_X_train,house_X_test)\n",
        "#house_X_test = standarization(house_X_test)\n",
        "print('when input data is standarized')\n",
        "print('for closed form solution')\n",
        "for lam in l:\n",
        "  print('when lambda equals to {0}'.format(lam))\n",
        "  start = t.time()\n",
        "  w,b = closed_form(house_X_train,house_y_train,lam)\n",
        "  end = t.time()\n",
        "  time_diff = end - start\n",
        "  print('time used equals to {0}'.format(time_diff))\n",
        "  print('the train loss is {0}'.format(loss_func(house_X_train,house_y_train,w,b,lam)))\n",
        "  print('the train error is {0}'.format(error_func(house_X_train,house_y_train,w,b)))\n",
        "  print('the test error is {0}'.format(error_func(house_X_test,house_y_test,w,b)))\n",
        "print('for gradient descent solution')\n",
        "for lam in l:\n",
        "  print('when lambda equals to {0}'.format(lam))\n",
        "  start = t.time()\n",
        "  loss_train,error_train,error_test,w,b = ridge_regression(house_X_train,house_y_train,house_X_test,house_y_test,max_pass=500,eta=0.01,tol=0.000001,lam=lam)\n",
        "  end = t.time()\n",
        "  time_diff = end -start\n",
        "  print('time used equals to {0}'.format(time_diff))\n",
        "  print('the train error is {0}'.format(error_func(house_X_train,house_y_train,w,b)))\n",
        "  print('the test error is {0}'.format(error_func(house_X_test,house_y_test,w,b)))\n",
        "  plt.figure()\n",
        "  plt.plot(loss_train)\n",
        "  plt.xlabel('passes')\n",
        "  plt.ylabel('train loss')\n",
        "  plt.title('passes vs. train loss')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "IeX75pnx3Co9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "##########################exercise 3######################################\n",
        "X_train_A = np.loadtxt('./X_train_A.csv',delimiter=',')\n",
        "X_train_B = np.loadtxt('./X_train_B.csv',delimiter=',')\n",
        "X_train_C = np.loadtxt('./X_train_C.csv',delimiter=',')\n",
        "Y_train_A = np.loadtxt('./Y_train_A.csv',delimiter=',')\n",
        "Y_train_B = np.loadtxt('./Y_train_B.csv',delimiter=',')\n",
        "Y_train_C = np.loadtxt('./Y_train_C.csv',delimiter=',')\n",
        "X_test_A = np.loadtxt('./X_test_A.csv',delimiter=',')\n",
        "X_test_B = np.loadtxt('./X_test_B.csv',delimiter=',')\n",
        "X_test_C = np.loadtxt('./X_test_C.csv',delimiter=',')\n",
        "Y_test_A = np.loadtxt('./Y_test_A.csv',delimiter=',')\n",
        "Y_test_B = np.loadtxt('./Y_test_B.csv',delimiter=',')\n",
        "Y_test_C = np.loadtxt('./Y_test_C.csv',delimiter=',')\n",
        "X_train_A = np.mat(X_train_A)\n",
        "X_train_B = np.mat(X_train_B)\n",
        "X_train_C = np.mat(X_train_C)\n",
        "Y_train_A = np.mat(Y_train_A).T\n",
        "Y_train_B = np.mat(Y_train_B).T\n",
        "Y_train_C = np.mat(Y_train_C).T\n",
        "X_test_A = np.mat(X_test_A)\n",
        "X_test_B = np.mat(X_test_B)\n",
        "X_test_C = np.mat(X_test_C)\n",
        "Y_test_A = np.mat(Y_test_A).T\n",
        "Y_test_B = np.mat(Y_test_B).T\n",
        "Y_test_C = np.mat(Y_test_C).T\n",
        "LAM= [1e-3, 1e-2, 0.5, 1, 2, 5, 10, 15, 20, 30, 50]\n",
        "K = 10\n",
        "def kfold(X,Y,k,i):\n",
        "  n,d = X.shape\n",
        "  #seperate n rows data into k parts, each part has num rows\n",
        "  num = n // k \n",
        "  train = list(range(0, i*num)) + list(range((i+1)*num, n))\n",
        "  test = list(range(i * num, (i + 1) * num if (i + 1) * num < n else n))\n",
        "  X_train = np.ndarray((len(train), d))\n",
        "  X_test = np.ndarray((len(test), d))\n",
        "  Y_train = np.ndarray((len(train), 1))\n",
        "  Y_test = np.ndarray((len(test), 1))\n",
        "  count = 0\n",
        "  for j in train:\n",
        "    X_train[count] = X[j]\n",
        "    Y_train[count] = Y[j]\n",
        "    count += 1\n",
        "  count = 0\n",
        "  for k in test: \n",
        "    X_test[count] = X[k]\n",
        "    Y_test[count] = Y[k]\n",
        "    count += 1\n",
        "  return X_train, X_test, Y_train, Y_test\n",
        "def linear_regression(X,Y):\n",
        "  reg = linear_model.LinearRegression()\n",
        "  model = reg.fit(X,np.array(Y.T)[0])\n",
        "  return model,np.append(reg.coef_, reg.intercept_)\n",
        "\n",
        "def ridge_regression(X,Y,LAM,K):\n",
        "  error = []\n",
        "  for l in LAM:\n",
        "    error_lam = []\n",
        "    for i in range(K):\n",
        "      X_train, X_test, Y_train, Y_test = kfold(X, Y, K, i)\n",
        "      reg_i = linear_model.Ridge(alpha=l)\n",
        "      model = reg_i.fit(X_train, np.array(Y_train.T)[0])\n",
        "      Y_hat = model.predict(X_test)\n",
        "      error_i = mean_squared_error(np.array(Y_test.T)[0], np.array(Y_hat))\n",
        "      error_lam.append(error_i)\n",
        "    mean_error = np.mean(error_lam)\n",
        "    error.append(mean_error)\n",
        "  min_error = min(error)\n",
        "  min_index = error.index(min_error)\n",
        "  min_lam = LAM[min_index]\n",
        "  reg = linear_model.Ridge(alpha=min_lam)\n",
        "  model = reg.fit(X, np.array(Y.T)[0]) \n",
        "  return model, np.append(reg.coef_, reg.intercept_), min_lam\n",
        "\n",
        "def Lasso_regression(X,Y,LAM,K):\n",
        "  error = []\n",
        "  for l in LAM:\n",
        "    error_lam = []\n",
        "    for i in range(K):\n",
        "      X_train, X_test, Y_train, Y_test = kfold(X, Y, K, i)\n",
        "      reg_i =linear_model.Lasso(alpha=l)\n",
        "      model = reg_i.fit(X_train, np.array(Y_train.T)[0])\n",
        "      Y_hat = model.predict(X_test)\n",
        "      error_i = mean_squared_error(np.array(Y_test.T)[0], np.array(Y_hat))\n",
        "      error_lam.append(error_i)\n",
        "    mean_error = np.mean(error_lam)\n",
        "    error.append(mean_error)\n",
        "  min_error = min(error)\n",
        "  min_index = error.index(min_error)\n",
        "  min_lam = LAM[min_index]\n",
        "  reg = linear_model.Lasso(alpha=min_lam)\n",
        "  model = reg.fit(X, np.array(Y.T)[0])\n",
        "  return model, np.append(reg.coef_, reg.intercept_), min_lam\n",
        "def test_error(model, X, Y):\n",
        "  Y_hat = model.predict(X)\n",
        "  error = mean_squared_error(np.array(Y.T)[0], np.array(Y_hat))\n",
        "  return error"
      ],
      "metadata": {
        "id": "_3xEveDCeH3R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_A_linear, w_A_linear= linear_regression(X_train_A, Y_train_A)\n",
        "model_A_ridge, w_A_ridge, lam_A_ridge = ridge_regression(X_train_A, Y_train_A, LAM, K)\n",
        "model_A_lasso, w_A_lasso, lam_A_lasso = Lasso_regression(X_train_A, Y_train_A, LAM, K)\n",
        "model_B_linear, w_B_linear = linear_regression(X_train_B, Y_train_B)\n",
        "model_B_ridge, w_B_ridge, lam_B_ridge = ridge_regression(X_train_B, Y_train_B, LAM, K)\n",
        "model_B_lasso, w_B_lasso, lam_B_lasso = Lasso_regression(X_train_B, Y_train_B, LAM, K)\n",
        "model_C_linear, w_C_linear = linear_regression(X_train_C, Y_train_C)\n",
        "model_C_ridge, w_C_ridge, lam_C_ridge = ridge_regression(X_train_C, Y_train_C, LAM, K)\n",
        "model_C_lasso, w_C_lasso, lam_C_lasso = Lasso_regression(X_train_C, Y_train_C, LAM, K)\n",
        "Error_A_linear = test_error(model_A_linear, X_test_A, Y_test_A)\n",
        "Error_A_ridge = test_error(model_A_ridge, X_test_A, Y_test_A)\n",
        "Error_A_lasso = test_error(model_A_lasso, X_test_A, Y_test_A)\n",
        "Error_B_linear = test_error(model_B_linear, X_test_B, Y_test_B)\n",
        "Error_B_ridge = test_error(model_B_ridge, X_test_B, Y_test_B)\n",
        "Error_B_lasso = test_error(model_B_lasso, X_test_B, Y_test_B)\n",
        "Error_C_linear = test_error(model_C_linear, X_test_C, Y_test_C)\n",
        "Error_C_ridge = test_error(model_C_ridge, X_test_C, Y_test_C)\n",
        "Error_C_lasso = test_error(model_C_lasso, X_test_C, Y_test_C)\n",
        "#ridge vs. lasso\n",
        "print('test error for A using linear: {0}'.format(Error_A_linear))\n",
        "print('Best lambada for A using ridge: {0}'.format(lam_A_ridge))\n",
        "print('test error for A using ridge: {0}'.format(Error_A_ridge))\n",
        "print('Best lambada for A using lasso: {0}'.format(lam_A_lasso))\n",
        "print('test error for A using lasso: {0}'.format(Error_A_lasso))\n",
        "print('\\n')\n",
        "print('test error for B using linear: {0}'.format(Error_B_linear))\n",
        "print('Best lambada for B using ridge: {0}'.format(lam_B_ridge))\n",
        "print('test error for B using ridge: {0}'.format(Error_B_ridge))\n",
        "print('Best lambada for B using lasso: {0}'.format(lam_B_lasso))\n",
        "print('test error for B using lasso: {0}'.format(Error_B_lasso))\n",
        "print('\\n')\n",
        "print('test error for C using linear: {0}'.format(Error_C_linear))\n",
        "print('Best lambada for C using ridge: {0}'.format(lam_C_ridge))\n",
        "print('test error for C using ridge: {0}'.format(Error_C_ridge))\n",
        "print('Best lambada for C using lasso: {0}'.format(lam_C_lasso))\n",
        "print('test error for C using lasso: {0}'.format(Error_C_lasso))\n",
        "print('\\n')\n",
        "#plot histogram graph\n",
        "plt.hist(w_A_linear, alpha = 0.5, label='linear') \n",
        "plt.hist(w_A_ridge, alpha = 0.5, label='ridge') \n",
        "plt.hist(w_A_lasso, alpha = 0.5, label='lasso')\n",
        "plt.legend()\n",
        "plt.title('appear times of w solved from 3 method with data A')\n",
        "plt.show()\n",
        "plt.hist(w_B_linear, alpha = 0.5, label='linear') \n",
        "plt.hist(w_B_ridge, alpha = 0.5, label='ridge') \n",
        "plt.hist(w_B_lasso, alpha = 0.5, label='lasso')\n",
        "plt.legend()\n",
        "plt.title('appear times of w solved from 3 method with data B')\n",
        "plt.show()\n",
        "plt.hist(w_C_linear, alpha = 0.5, label='linear') \n",
        "plt.hist(w_C_ridge, alpha = 0.5, label='ridge') \n",
        "plt.hist(w_C_lasso, alpha = 0.5, label='lasso')\n",
        "plt.legend()\n",
        "plt.title('appear times of w solved from 3 method with data C')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "coNDOyTcpyPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "##############################exercise 4##################################\n",
        "#Read csv file and store data in numpy format\n",
        "X_train_D = np.loadtxt('./X_train_D.csv',delimiter=',')\n",
        "X_train_E = np.loadtxt('./X_train_E.csv',delimiter=',')\n",
        "X_train_F = np.loadtxt('./X_train_F.csv',delimiter=',')\n",
        "Y_train_D = np.loadtxt('./Y_train_D.csv',delimiter=',')\n",
        "Y_train_E = np.loadtxt('./Y_train_E.csv',delimiter=',')\n",
        "Y_train_F = np.loadtxt('./Y_train_F.csv',delimiter=',')\n",
        "X_test_D = np.loadtxt('./X_test_D.csv',delimiter=',')\n",
        "X_test_E = np.loadtxt('./X_test_E.csv',delimiter=',')\n",
        "X_test_F = np.loadtxt('./X_test_F.csv',delimiter=',')\n",
        "Y_test_D = np.loadtxt('./Y_test_D.csv',delimiter=',')\n",
        "Y_test_E = np.loadtxt('./Y_test_E.csv',delimiter=',')\n",
        "Y_test_F = np.loadtxt('./Y_test_F.csv',delimiter=',')\n",
        "#tranform to numpy array format\n",
        "X_train_D = np.mat(X_train_D).T\n",
        "X_train_E = np.mat(X_train_E).T\n",
        "X_train_F = np.mat(X_train_F)\n",
        "Y_train_D = np.mat(Y_train_D).T\n",
        "Y_train_E = np.mat(Y_train_E).T\n",
        "Y_train_F = np.mat(Y_train_F).T\n",
        "X_test_D = np.mat(X_test_D).T\n",
        "X_test_E = np.mat(X_test_E).T\n",
        "X_test_F = np.mat(X_test_F)\n",
        "Y_test_D = np.mat(Y_test_D).T\n",
        "Y_test_E = np.mat(Y_test_E).T\n",
        "Y_test_F = np.mat(Y_test_F).T"
      ],
      "metadata": {
        "id": "ICEMUwTX6jBE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def KNN(X_in,X_dataSet,Y_dataSet,k):\n",
        "  size = X_dataSet.shape[0]\n",
        "  y_out = []\n",
        "  for n in range(X_in.shape[0]):\n",
        "    X_test = X_in[n][:]\n",
        "    diff = np.tile(X_test,(size,1)) - X_dataSet\n",
        "    diff = np.power(diff,2)\n",
        "    dist = diff.sum(axis=1)\n",
        "    dist = np.power(dist,0.5)\n",
        "    sortIndex = np.argsort(dist,axis=0)\n",
        "    sum_y = 0\n",
        "    for j in range(k):\n",
        "      sum_y += Y_dataSet[sortIndex[j,0],0]\n",
        "    y_pred = sum_y/k\n",
        "    y_out.append(y_pred)\n",
        "  y_out = np.array(y_out)\n",
        "  return np.mat(y_out).T\n",
        "#least square solution is just closed form solution with lambda equals to 0\n",
        "def closed_form(X,y,X_in,lam=0):\n",
        "  n,d = X.shape\n",
        "  n_ones = np.ones(y.shape)\n",
        "  d_ones = np.ones((d,1))\n",
        "  X_2 = X.T.dot(X) #d*d\n",
        "  X_y = X.T.dot(y) #d*1\n",
        "  for i in range(X_2.shape[0]):\n",
        "    X_2[i,i] += 2*n*lam\n",
        "  b_vec = np.dot(X.T,n_ones) #d*1\n",
        "  X_2 = np.append(X_2,b_vec,axis=1)\n",
        "  a = X\n",
        "  a = np.append(a,n_ones,axis=1)\n",
        "  a = n_ones.T.dot(a)\n",
        "  b = n_ones.T*y\n",
        "  a = np.append(X_2,a,axis=0)\n",
        "  b = np.append(X_y,b,axis=0)\n",
        "  ans = np.linalg.solve(a,b)\n",
        "  w = ans[0:-1,0]\n",
        "  b = ans[-1,0]\n",
        "  ones = np.ones((X_in.shape[0],1))\n",
        "  y_pred = np.dot(X_in,w) + b*ones\n",
        "  return y_pred\n",
        "def error_func(Y_pred, Y):\n",
        "  return np.power(np.linalg.norm(Y_pred - Y, ord=2), 2) / len(Y)\n",
        "def quest2(X_train,Y_train,X_test,Y_test):\n",
        "  x_max = np.max(X_train)\n",
        "  x_min = np.min(X_train)\n",
        "  x_in = list(range(int(x_min / 0.01), int(x_max / 0.01)))\n",
        "  x_in = np.reshape(x_in, (len(x_in), 1))\n",
        "  x_in = x_in * 0.01\n",
        "  least_y_pred = closed_form(X_train,Y_train,x_in)\n",
        "  knn_1_pred = KNN(x_in,X_train,Y_train,1)\n",
        "  knn_9_pred = KNN(x_in,X_train,Y_train,9)\n",
        "  plt.scatter(np.array(X_train).flatten(),np.array(Y_train).flatten())\n",
        "  plt.plot(x_in,least_y_pred,label = 'linear')\n",
        "  plt.plot(x_in,knn_1_pred,label = 'knn_1')\n",
        "  plt.plot(x_in,knn_9_pred,label = 'knn_9')\n",
        "  plt.xlabel('input x')\n",
        "  plt.ylabel('predict y')\n",
        "  plt.legend()\n",
        "  plt.title('input x vs predit y coming from least square regression and KNN regression with k=1 and k=9')\n",
        "  plt.show()\n",
        "  k_choose = []\n",
        "  error = []\n",
        "  for i in range(9):\n",
        "    knn_pred = KNN(X_test,X_train,Y_train,(i+1))\n",
        "    ans = error_func(knn_pred,Y_test)\n",
        "    k_choose.append(i+1)\n",
        "    error.append(ans)\n",
        "  least_error = error_func(closed_form(X_train,Y_train,X_test),Y_test)\n",
        "  plt.plot(range(1,10),np.ones(9)*least_error,label = 'linear')\n",
        "  plt.bar(k_choose,error,alpha=0.4,label = 'knn')\n",
        "  plt.legend()\n",
        "  plt.title('test error for KNN with k from 1 to 9 and also for least square regression')\n",
        "  plt.xlabel('k')\n",
        "  plt.ylabel('test error')\n",
        "  plt.show()\n",
        "def quest3(X_train,Y_train,X_test,Y_test):\n",
        "  k_choose = []\n",
        "  error = []\n",
        "  for i in range(9):\n",
        "    knn_pred = KNN(X_test,X_train,Y_train,(i+1))\n",
        "    ans = error_func(knn_pred,Y_test)\n",
        "    k_choose.append(i+1)\n",
        "    error.append(ans)\n",
        "  least_error = error_func(closed_form(X_train,Y_train,X_test),Y_test)\n",
        "  plt.plot(range(1,10),np.ones(9)*least_error,label = 'linear')\n",
        "  plt.bar(k_choose,error,alpha=0.4,label = 'knn')\n",
        "  plt.legend()\n",
        "  plt.title('test error for KNN with k from 1 to 9 and also for least square regression')\n",
        "  plt.xlabel('k')\n",
        "  plt.ylabel('test error')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "asq4MsokyaYm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('for data D')\n",
        "print('\\n')\n",
        "quest2(X_train_D,Y_train_D,X_test_D,Y_test_D)\n",
        "print('for data E')\n",
        "print('\\n')\n",
        "quest2(X_train_E,Y_train_E,X_test_E,Y_test_E)\n",
        "print('for data F')\n",
        "print('\\n')\n",
        "quest3(X_train_F,Y_train_F,X_test_F,Y_test_F)"
      ],
      "metadata": {
        "id": "uNdoPJIv8bGA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}